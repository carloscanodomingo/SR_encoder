{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "STAT 453: Deep Learning (Spring 2021)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_data_loader import get_dataloaders_mnist, read_sr_data, transform_data\n",
    "from helper_utils import set_deterministic, set_all_seeds\n",
    "from helper_train import train_autoencoder_v1, get_est, get_data_complete, train_vae_v1, train_v1\n",
    "from helper_plotting import plot_latent_space_with_labels, plot_frequencies, plot_loss, plot_freq_loss, plot_season, plot_training_loss, plot_cases, plot_residual_loss, plot_noise\n",
    "from helper_metrics import corr_noise\n",
    "from helper_log_model import log_result\n",
    "from helper_models import VQVAE, VAE, AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"\"#'D:\\GIT\\pytorch\\dl_python'\n",
    "component = \"EW\"\n",
    "data_path = 'data'\n",
    "fit_sr = '\\\\SR_table_' + component +'_DL.mat'\n",
    "filepath = root+ data_path + fit_sr;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "DEVICE_CPU = \"cpu\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 123\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32 * 20\n",
    "NUM_EPOCHS = 100\n",
    "num_hiddens = 64\n",
    "latent_dim = 10\n",
    "kernel_size = 32\n",
    "regression_hidden = 128\n",
    "freq_mult = 100\n",
    "dropout = 0.0\n",
    "SWEEP = 0\n",
    "SAVE_DATA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"kernel_size\": kernel_size,\n",
    "    \"num_hiddens\": num_hiddens,\n",
    "    \"lantent_dim\": latent_dim,\n",
    "    \"regression_hidden\":regression_hidden,\n",
    "    \"freq_mult\": freq_mult,\n",
    "     \"dropout\": dropout,\n",
    "    \"best_perc\": 20,\n",
    "    \"type\": \"NO_RAW\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_deterministic\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281,)\n",
      "bool\n",
      "(40055, 512)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### Dataset\n",
    "##########################\n",
    "\n",
    "train_loader, test_loader, fixed_normal_data, normal_loader = get_dataloaders_mnist(filepath ,batch_size = BATCH_SIZE, case = \"NORMAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281,)\n",
      "bool\n",
      "(10577, 512)\n"
     ]
    }
   ],
   "source": [
    "train_loader_worst, test_loader_worst, fixed_worst_data, worst_loader = get_dataloaders_mnist(filepath, batch_size = BATCH_SIZE,  case = \"WORST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281,)\n",
      "bool\n",
      "(79281, 512)\n"
     ]
    }
   ],
   "source": [
    "_, _, _, all_loader = get_dataloaders_mnist(filepath, batch_size = BATCH_SIZE,  case = \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "data raw dimensions: torch.Size([640, 1, 256])\n",
      "data lorentz dimensions: torch.Size([640, 1, 256])\n",
      "Freq  dimensions: torch.Size([640, 6])\n",
      "label dimensions: torch.Size([640])\n",
      "tensor([[[0.9050, 1.0000, 0.8184,  ..., 0.1939, 0.1213, 0.0413]],\n",
      "\n",
      "        [[0.7723, 0.6929, 0.7319,  ..., 0.2167, 0.1728, 0.0889]],\n",
      "\n",
      "        [[0.8146, 0.8118, 0.8859,  ..., 0.0976, 0.0694, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7722, 0.9648, 0.8685,  ..., 0.1396, 0.0948, 0.0374]],\n",
      "\n",
      "        [[0.9261, 0.8936, 0.8567,  ..., 0.2271, 0.1336, 0.1004]],\n",
      "\n",
      "        [[1.0000, 0.9721, 0.8276,  ..., 0.1427, 0.0981, 0.0235]]])\n",
      "Train len: 26240\n",
      "Classes: 4\n",
      "\n",
      "Testing Set:\n",
      "data raw dimensions: torch.Size([640, 1, 256])\n",
      "data lorentz dimensions: torch.Size([640, 1, 256])\n",
      "Freq  dimensions: torch.Size([640, 6])\n",
      "label dimensions: torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for data_raw, data_lorentz,values_freq, labels in train_loader:  \n",
    "    print('data raw dimensions:', data_raw.size())\n",
    "    batch_size = data_raw.size()[0]\n",
    "    print('data lorentz dimensions:', data_lorentz.size())\n",
    "    print('Freq  dimensions:', values_freq.size())\n",
    "    print('label dimensions:', labels.size())\n",
    "    NUM_CLASSES = len(numpy.unique(labels))\n",
    "    print(data_raw[:10])\n",
    "    break\n",
    "print(\"Train len: \"  + str(len(train_loader) * batch_size))\n",
    "print(\"Classes: \"  + str(NUM_CLASSES))\n",
    "# Checking the dataset\n",
    "print('\\nTesting Set:')\n",
    "for data_raw, data_lorentz,values_freq,  labels in test_loader:  \n",
    "    print('data raw dimensions:', data_raw.size())\n",
    "    print('data lorentz dimensions:', data_lorentz.size())\n",
    "    print('Freq  dimensions:', values_freq.size())\n",
    "    print('label dimensions:', labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VQ-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCL -> BLC\n",
    "        inputs = inputs.permute(0, 2, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        #print(input_shape)\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        # convert quantized from BLC -> BCL\n",
    "        return loss, quantized.permute(0, 2, 1).contiguous(), perplexity, encodings\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, num_embeddings, dropout = 0, commitment_cost = 0.25):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential( #784\n",
    "            nn.Conv1d(in_channels=1,\n",
    "                  out_channels=num_hiddens // 2,\n",
    "                  kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                  out_channels=num_hiddens,\n",
    "                  kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv1d(in_channels=num_hiddens,\n",
    "                  out_channels=num_hiddens,\n",
    "                  kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "        )\n",
    "        self.pre_vq_conv = nn.Conv1d(in_channels=num_hiddens, \n",
    "                                  out_channels=latent_dim,\n",
    "                                  kernel_size=1, \n",
    "                                  stride=1)\n",
    "        \n",
    "        self.vq_vae = VectorQuantizer(num_embeddings, latent_dim,\n",
    "                                       commitment_cost)\n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(latent_dim * (data_len // (2 ** 3)), regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=latent_dim,\n",
    "                         out_channels=num_hiddens,\n",
    "                         kernel_size=3, \n",
    "                         stride=1, padding=1),\n",
    "            #torch.nn.Linear(num_hiddens, num_hiddens * (data_len // (2 ** 3))),\n",
    "            Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "            nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                  out_channels=num_hiddens,\n",
    "                  kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                  out_channels=num_hiddens // 2,\n",
    "                  kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                  out_channels=1,\n",
    "                  kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(dropout),\n",
    "            Trim(),  # 1x29x29 -> 1x28x28\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z = self.pre_vq_conv(x)\n",
    "        loss, encoded, perplexity, encoding = self.vq_vae(z)\n",
    "        #print(encoded.shape)\n",
    "        freq = self.regresion(encoded)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded,perplexity,loss,freq, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #784\n",
    "                nn.Conv1d(in_channels=1,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim),\n",
    "        )\n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Linear(latent_dim , regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(latent_dim, num_hiddens * (data_len // (2 ** 3))),\n",
    "                Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                Trim(),  # 1x29x29 -> 1x28x28\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        freq = self.regresion(encoder)\n",
    "        decoder = self.decoder(encoder)\n",
    "        return encoder,None, None, freq, decoder\n",
    "    \n",
    "    \n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "\n",
    "class Trim(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #784\n",
    "                nn.Conv1d(in_channels=1,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Flatten(),\n",
    "        )\n",
    "        self.z_mean = torch.nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim)\n",
    "        self.z_log_var = torch.nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim)\n",
    "        \n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Linear(latent_dim , regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(latent_dim, num_hiddens * (data_len // (2 ** 3))),\n",
    "                Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                Trim(),  # 1x29x29 -> 1x28x28\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "    def encoding_fn(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        return encoded\n",
    "    def reparameterize(self, z_mu, z_log_var):\n",
    "        eps = torch.randn(z_mu.size(0), z_mu.size(1), device=z_mu.device)\n",
    "        z = z_mu + eps * torch.exp(z_log_var/2.) \n",
    "        return z\n",
    "    def latent_sample(self, z_mu, z_log_var):\n",
    "        # the reparameterization trick\n",
    "        std = z_log_var.mul(0.5).exp_()\n",
    "        eps = torch.empty_like(std).normal_()\n",
    "        return eps.mul(std).add_(z_mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.latent_sample(z_mean, z_log_var)\n",
    "        freq = self.regresion(encoded)#torch.cat((z_mean, z_log_var), dim = 1))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded,z_mean,z_log_var,freq, decoded\n",
    "\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #784\n",
    "                nn.Conv1d(in_channels=1,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim),\n",
    "        )\n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Linear(latent_dim , regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(latent_dim, num_hiddens * (data_len // (2 ** 3))),\n",
    "                Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                Trim(),  # 1x29x29 -> 1x28x28\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        freq = self.regresion(encoder)\n",
    "        decoder = self.decoder(encoder)\n",
    "        return encoder,None, None, freq, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 32, 128]           1,024\n",
      "       BatchNorm1d-2              [-1, 32, 128]              64\n",
      "         LeakyReLU-3              [-1, 32, 128]               0\n",
      "           Dropout-4              [-1, 32, 128]               0\n",
      "            Conv1d-5               [-1, 64, 64]          32,768\n",
      "         LeakyReLU-6               [-1, 64, 64]               0\n",
      "            Conv1d-7               [-1, 64, 32]          32,768\n",
      "       BatchNorm1d-8               [-1, 64, 32]             128\n",
      "         LeakyReLU-9               [-1, 64, 32]               0\n",
      "          Flatten-10                 [-1, 2048]               0\n",
      "           Linear-11                   [-1, 10]          20,490\n",
      "           Linear-12                  [-1, 128]           1,408\n",
      "           Linear-13                    [-1, 6]             774\n",
      "          Sigmoid-14                    [-1, 6]               0\n",
      "           Linear-15                 [-1, 2048]          22,528\n",
      "          Reshape-16               [-1, 64, 32]               0\n",
      "  ConvTranspose1d-17               [-1, 64, 64]          32,768\n",
      "      BatchNorm1d-18               [-1, 64, 64]             128\n",
      "        LeakyReLU-19               [-1, 64, 64]               0\n",
      "  ConvTranspose1d-20              [-1, 32, 128]          32,768\n",
      "      BatchNorm1d-21              [-1, 32, 128]              64\n",
      "        LeakyReLU-22              [-1, 32, 128]               0\n",
      "  ConvTranspose1d-23               [-1, 1, 256]           1,024\n",
      "        LeakyReLU-24               [-1, 1, 256]               0\n",
      "          Dropout-25               [-1, 1, 256]               0\n",
      "             Trim-26               [-1, 1, 256]               0\n",
      "          Sigmoid-27               [-1, 1, 256]               0\n",
      "================================================================\n",
      "Total params: 178,704\n",
      "Trainable params: 178,704\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 0.68\n",
      "Estimated Total Size (MB): 1.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "data_len = 256\n",
    "encoded_type = \"RAW\"\n",
    "model_type = \"AE\"\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "model = AutoEncoder(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim, \n",
    "                         regression_hidden = regression_hidden, dropout = dropout)\n",
    "\n",
    "summary(model, (1,256), batch_size=-1, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mual-ucv-uma\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ual-ucv-uma/VAE/runs/1jcwmz5m\" target=\"_blank\">fresh-frost-2</a></strong> to <a href=\"https://wandb.ai/ual-ucv-uma/VAE\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ual-ucv-uma/VAE/runs/1jcwmz5m?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1b7998389a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len = 256\n",
    "encoded_type = \"RAW\"\n",
    "model_type = \"VAE\"\n",
    "SWEEP = 0\n",
    "wandb.init(project=\"VAE\", notes=\"EW\",tags=[\"VAE\", \"paper7\"],config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2000\n",
    "SAVE_DATA = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6",
    "tags": []
   },
   "source": [
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.14 min\n",
      "Epocah: 001/2000 | Loss: 0.3429 | Loss_freq: 0.2403 | Loss_ae: 0.0555 | kl_div 0.0471 | Worst_Loss: 0.0555 | Worst_Loss_freq: 0.0776 | Worst_Loss_ae: 0.1331 |\n",
      "Time elapsed: 15.16 min\n",
      "Epocah: 201/2000 | Loss: 0.0457 | Loss_freq: 0.0295 | Loss_ae: 0.0023 | kl_div 0.0138 | Worst_Loss: 0.0247 | Worst_Loss_freq: 0.0082 | Worst_Loss_ae: 0.0330 |\n",
      "Time elapsed: 30.20 min\n",
      "Epocah: 401/2000 | Loss: 0.1214 | Loss_freq: 0.0917 | Loss_ae: 0.0032 | kl_div 0.0265 | Worst_Loss: 0.0320 | Worst_Loss_freq: 0.0094 | Worst_Loss_ae: 0.0415 |\n",
      "Time elapsed: 45.25 min\n",
      "Epocah: 601/2000 | Loss: 0.0388 | Loss_freq: 0.0270 | Loss_ae: 0.0021 | kl_div 0.0097 | Worst_Loss: 0.0229 | Worst_Loss_freq: 0.0077 | Worst_Loss_ae: 0.0306 |\n",
      "Time elapsed: 60.31 min\n",
      "Epocah: 801/2000 | Loss: 0.0320 | Loss_freq: 0.0194 | Loss_ae: 0.0022 | kl_div 0.0104 | Worst_Loss: 0.0274 | Worst_Loss_freq: 0.0077 | Worst_Loss_ae: 0.0351 |\n",
      "Time elapsed: 75.36 min\n",
      "Epocah: 1001/2000 | Loss: 0.0253 | Loss_freq: 0.0128 | Loss_ae: 0.0019 | kl_div 0.0107 | Worst_Loss: 0.0403 | Worst_Loss_freq: 0.0079 | Worst_Loss_ae: 0.0482 |\n",
      "Time elapsed: 90.41 min\n",
      "Epocah: 1201/2000 | Loss: 0.0234 | Loss_freq: 0.0109 | Loss_ae: 0.0020 | kl_div 0.0105 | Worst_Loss: 0.0401 | Worst_Loss_freq: 0.0079 | Worst_Loss_ae: 0.0479 |\n",
      "Time elapsed: 105.46 min\n",
      "Epocah: 1401/2000 | Loss: 0.0225 | Loss_freq: 0.0099 | Loss_ae: 0.0021 | kl_div 0.0106 | Worst_Loss: 0.0428 | Worst_Loss_freq: 0.0082 | Worst_Loss_ae: 0.0509 |\n",
      "Time elapsed: 120.51 min\n",
      "Epocah: 1601/2000 | Loss: 0.0216 | Loss_freq: 0.0092 | Loss_ae: 0.0020 | kl_div 0.0104 | Worst_Loss: 0.0422 | Worst_Loss_freq: 0.0086 | Worst_Loss_ae: 0.0507 |\n",
      "Time elapsed: 135.57 min\n",
      "Epocah: 1801/2000 | Loss: 0.0215 | Loss_freq: 0.0085 | Loss_ae: 0.0021 | kl_div 0.0110 | Worst_Loss: 0.0415 | Worst_Loss_freq: 0.0088 | Worst_Loss_ae: 0.0504 |\n",
      "Total Training Time: 150.55 min\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_data_complete() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8236/1780613653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m                             logging_interval=200, wandb = wandb,model_type = model_type, encoded_type = encoded_type)\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mSAVE_DATA\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models/\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m\".model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mlog_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader_worst\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_data_complete() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "if SWEEP == 1:\n",
    "    sweep_config = {\n",
    "      \"name\" : \"regression_lantent\",\n",
    "      \"method\" : \"grid\",\n",
    "      \"parameters\" : {\n",
    "          \"num_embeddings\":{\n",
    "              \"values\" : [32]\n",
    "          },\n",
    "          \"commitment_cost\":{\n",
    "              \"values\" : [ 0.7]\n",
    "          },\n",
    "        \"encoded_type\" : {\n",
    "          \"values\" : ['RAW', 'LORENTZ']\n",
    "        },\n",
    "         \"model_type\" : {\n",
    "          \"values\" : [\"AE\",\"VAE\",\"VQVAE\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config)\n",
    "    def train():\n",
    "        config = {\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"epochs\": NUM_EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"kernel_size\": kernel_size,\n",
    "            \"num_hiddens\": num_hiddens,\n",
    "            \"lantent_dim\": latent_dim,\n",
    "            \"regression_hidden\":regression_hidden,\n",
    "            \"freq_mult\": freq_mult,\n",
    "             \"dropout\": dropout,\n",
    "            \"best_perc\": 20,\n",
    "        }\n",
    "        with wandb.init(project=\"Six Cases\", notes=\"FinishingResults\",tags=[\"VQVAEAE\", \"paper5\"],config=config) as run:\n",
    "            config = wandb.config\n",
    "            model_type =  config[\"model_type\"]\n",
    "            encoded_type = config[\"encoded_type\"]\n",
    "            if model_type == \"AE\":\n",
    "                model = AE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim, \n",
    "                                 regression_hidden = regression_hidden, dropout = dropout)\n",
    "            if model_type == \"VAE\":\n",
    "                model = VAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                            regression_hidden = regression_hidden, dropout = dropout)\n",
    "            if model_type == \"VQVAE\":\n",
    "                model = VQVAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                      regression_hidden = regression_hidden, num_embeddings = config[\"num_embeddings\"], dropout = 0, commitment_cost = config[\"commitment_cost\"])\n",
    "            model.to(DEVICE)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "            log_dict = train_v1(num_epochs=NUM_EPOCHS, model=model, \n",
    "                                    optimizer=optimizer, device=DEVICE, freq_mult = freq_mult,\n",
    "                                    train_loader=train_loader,\n",
    "                                    worst_case_loader = train_loader_worst,\n",
    "                                    skip_epoch_stats=True,\n",
    "                                    logging_interval=200, wandb = wandb, model_type = model_type, encoded_type = encoded_type)\n",
    "            if SAVE_DATA == 1:\n",
    "                data = get_data_complete(filepath, model, \"cpu\", )\n",
    "                torch.save(model, \"models/\"+ run.name + \".model\")\n",
    "                log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)\n",
    "\n",
    "    \n",
    "    wandb.agent(sweep_id, function=train)\n",
    "if SWEEP == 0:\n",
    "    from torchvision import models\n",
    "    from torchsummary import summary\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "    if model_type == \"AE\":\n",
    "        model = AE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim, \n",
    "                         regression_hidden = regression_hidden, dropout = dropout)\n",
    "    if model_type == \"VAE\":\n",
    "        model = VAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                    regression_hidden = regression_hidden, dropout = dropout)\n",
    "    if model_type == \"VQVAE\":\n",
    "        model = VQVAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                      regression_hidden = regression_hidden, num_embeddings = 32, dropout = 0, commitment_cost = 0.25)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "    #summary(model, (1,256), batch_size=-1, device='cuda')\n",
    "\n",
    "\n",
    "    log_dict = train_v1(num_epochs=NUM_EPOCHS, model=model, \n",
    "                            optimizer=optimizer, device=DEVICE, freq_mult = freq_mult,\n",
    "                            train_loader=train_loader,\n",
    "                            worst_case_loader = train_loader_worst,\n",
    "                            skip_epoch_stats=True,\n",
    "                            logging_interval=200, wandb = wandb,model_type = model_type, encoded_type = encoded_type)\n",
    "    if SAVE_DATA == 1:\n",
    "        data = get_data_complete(filepath, all_loader,  model, DEVICE)\n",
    "        torch.save(model, \"models/\"+ wandb.run.name + \"_\" + component +  \".model\")\n",
    "        log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/\"+ wandb.run.name + \"_\" + component +  \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQVAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "              regression_hidden = regression_hidden, embedding_dim = 64, num_embeddings = 32, dropout = 0)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "summary(model, (1,256), batch_size=-1, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = corr_noise(data)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"VAE\"\n",
    "encoded_type = \"RAW\"\n",
    "base_path = \"images/\" + model_type + \"_\" + encoded_type + \"_\";\n",
    "path_loss_batch = base_path + \"loss.png\"\n",
    "plot_loss(log_dict, NUM_EPOCHS, model_type).savefig(path_loss_batch)\n",
    "wandb.log({\"loss_batch\": wandb.Image(path_loss_batch)})\n",
    "\n",
    "path_worst_residual_freq_loss = base_path + \"worst_residual_freq_loss.png\"\n",
    "plot_residual_loss(test_loader_worst, model, DEVICE, model_type = model_type, show = False).savefig(path_worst_residual_freq_loss)\n",
    "wandb.log({\"worst_residual_freq_loss\": wandb.Image(path_worst_residual_freq_loss)})\n",
    "\n",
    "\n",
    "path_test_residual_freq_loss = base_path + \"test_residual_freq_loss.png\"\n",
    "plot_residual_loss(test_loader, model, DEVICE, model_type = model_type, show = False).savefig(path_test_residual_freq_loss)\n",
    "wandb.log({\"test_residual_freq_loss\": wandb.Image(path_test_residual_freq_loss)})\n",
    "\n",
    "path_train_freq_qqplot = base_path + \"train_freq_qqplot.png\"\n",
    "plot_freq_loss(train_loader, model, DEVICE, model_type = model_type, show = False).savefig(path_train_freq_qqplot)\n",
    "wandb.log({\"train_freq_qqplot\": wandb.Image(path_train_freq_qqplot)})\n",
    "\n",
    "path_worst_freq_qqplot = base_path + \"worst_freq_qqplot.png\"\n",
    "plot_freq_loss(train_loader_worst, model, DEVICE, model_type = model_type, show = False).savefig(path_worst_freq_qqplot)\n",
    "wandb.log({\"worst_freq_qqplot\": wandb.Image(path_worst_freq_qqplot)})\n",
    "\n",
    "path_worst_cases = base_path + \"worst_cases.png\"\n",
    "plot_cases(test_loader_worst, model, DEVICE, model_type = model_type).savefig(path_worst_cases)\n",
    "wandb.log({\"worst_cases\": wandb.Image(path_worst_cases)})\n",
    "\n",
    "path_test_cases = base_path + \"test_cases.png\"\n",
    "plot_cases(test_loader, model, DEVICE, model_type = model_type).savefig(path_test_cases)\n",
    "wandb.log({\"test_cases\": wandb.Image(path_test_cases)})\n",
    "\n",
    "dict_freq = selected_freq(data)\n",
    "\n",
    "path_hist_freq = base_path + \"hist_freq.png\"\n",
    "plot_hist_freq(data).savefig(path_hist_freq)\n",
    "wandb.log({\"hist_freq\": wandb.Image(path_hist_freq)})\n",
    "\n",
    "for index_sr_mode in range(1,7):\n",
    "    freq_qqplot = base_path + str(index_sr_mode) + \"_freq_qqplot.png\"\n",
    "    plot_season(data, sr_mode=index_sr_mode, show = False).savefig(freq_qqplot)\n",
    "    wandb.log({ str(index_sr_mode) + \"_freq_qqplot\": wandb.Image(freq_qqplot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_log_model import log_result\n",
    "from sklearn import preprocessing    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = read_sr_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281, 512)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"models/AE_RAW.model\")\n",
    "data = get_data_complete(filepath, model, \"cpu\")\n",
    "List = [model, data];\n",
    "Dict = {\"AE_RAW\":List}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_models import VQVAE, VAE, AutoEncoder, Reshape, Trim, VectorQuantizer\n",
    "model = torch.load(\"models/VQVAE_RAW.model\")\n",
    "values =  get_est(all_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/AE_RAW.model\n",
      "models/VAE_RAW.model\n"
     ]
    }
   ],
   "source": [
    "from helper_models import VQVAE, VAE, AutoEncoder, Reshape, Trim, VectorQuantizer\n",
    "from helper_train import get_data_complete\n",
    "import torch\n",
    "# load pickle module\n",
    "import pickle\n",
    "\n",
    "root = \"\"\n",
    "data_path = 'data'\n",
    "fit_sr = '\\\\SR_table_DL.mat'\n",
    "datapath = filepath = root + data_path + fit_sr;\n",
    "start_model_path = \"models/\"\n",
    "end_model_path = \".model\"\n",
    "models = [\"AE_RAW\", \"VAE_RAW\", \"VQVAE_RAW\", \"AE_LORENTZ\", \"VAE_LORENTZ\", \"VQVAE_LORENTZ\"]\n",
    "models_dict = {}\n",
    "for index_model in range(6):\n",
    "    model_name = models[index_model] \n",
    "    model_path = start_model_path + model_name + end_model_path\n",
    "    print(model_path)\n",
    "    model = torch.load(model_path)\n",
    "    data = get_data_complete(filepath, all_loader, model, \"cpu\")\n",
    "    current_dict = {\"model\": model, \"data\": data}\n",
    "    models_dict[model_name] = current_dict\n",
    "        \n",
    "# create a binary pickle file \n",
    "f = open(\"models.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(models_dict,f)\n",
    "\n",
    "# close file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "branch-env",
   "language": "python",
   "name": "branch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
