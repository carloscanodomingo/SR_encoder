{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "STAT 453: Deep Learning (Spring 2021)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_data_loader import get_dataloaders_mnist, read_sr_data, transform_data\n",
    "from helper_utils import set_deterministic, set_all_seeds\n",
    "from helper_train import train_autoencoder_v1, get_est, get_data_complete, train_vae_v1, train_v1\n",
    "from helper_plotting import plot_latent_space_with_labels, plot_frequencies, plot_loss, plot_freq_loss, plot_season, plot_training_loss, plot_cases, plot_residual_loss, plot_noise\n",
    "from helper_metrics import corr_noise\n",
    "from helper_log_model import log_result\n",
    "from helper_models import VQVAE, VAE, AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"\"#'D:\\GIT\\pytorch\\dl_python'\n",
    "data_path = 'data'\n",
    "fit_sr = '\\\\SR_table_DL.mat'\n",
    "filepath = root+ data_path + fit_sr;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "DEVICE_CPU = \"cpu\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 123\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32 * 20\n",
    "NUM_EPOCHS = 100\n",
    "num_hiddens = 64\n",
    "latent_dim = 10\n",
    "kernel_size = 32\n",
    "regression_hidden = 128\n",
    "freq_mult = 100\n",
    "dropout = 0.0\n",
    "SWEEP = 0\n",
    "SAVE_DATA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"kernel_size\": kernel_size,\n",
    "    \"num_hiddens\": num_hiddens,\n",
    "    \"lantent_dim\": latent_dim,\n",
    "    \"regression_hidden\":regression_hidden,\n",
    "    \"freq_mult\": freq_mult,\n",
    "     \"dropout\": dropout,\n",
    "    \"best_perc\": 20,\n",
    "    \"type\": \"NO_RAW\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_deterministic\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281,)\n",
      "bool\n",
      "(12849, 512)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### Dataset\n",
    "##########################\n",
    "\n",
    "train_loader, test_loader, fixed_normal_data, normal_loader = get_dataloaders_mnist(filepath ,batch_size = BATCH_SIZE, case = \"NORMAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281,)\n",
      "bool\n",
      "(18167, 512)\n"
     ]
    }
   ],
   "source": [
    "train_loader_worst, test_loader_worst, fixed_worst_data, worst_loader = get_dataloaders_mnist(filepath, batch_size = BATCH_SIZE,  case = \"WORST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281,)\n",
      "bool\n",
      "(79281, 512)\n"
     ]
    }
   ],
   "source": [
    "_, _, _, all_loader = get_dataloaders_mnist(filepath, batch_size = BATCH_SIZE,  case = \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for data_raw, data_lorentz,values_freq, labels in train_loader:  \n",
    "    print('data raw dimensions:', data_raw.size())\n",
    "    batch_size = data_raw.size()[0]\n",
    "    print('data lorentz dimensions:', data_lorentz.size())\n",
    "    print('Freq  dimensions:', values_freq.size())\n",
    "    print('label dimensions:', labels.size())\n",
    "    NUM_CLASSES = len(numpy.unique(labels))\n",
    "    print(data_raw[:10])\n",
    "    break\n",
    "print(\"Train len: \"  + str(len(train_loader) * batch_size))\n",
    "print(\"Classes: \"  + str(NUM_CLASSES))\n",
    "# Checking the dataset\n",
    "print('\\nTesting Set:')\n",
    "for data_raw, data_lorentz,values_freq,  labels in test_loader:  \n",
    "    print('data raw dimensions:', data_raw.size())\n",
    "    print('data lorentz dimensions:', data_lorentz.size())\n",
    "    print('Freq  dimensions:', values_freq.size())\n",
    "    print('label dimensions:', labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VQ-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCL -> BLC\n",
    "        inputs = inputs.permute(0, 2, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        #print(input_shape)\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        # convert quantized from BLC -> BCL\n",
    "        return loss, quantized.permute(0, 2, 1).contiguous(), perplexity, encodings\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, num_embeddings, dropout = 0, commitment_cost = 0.25):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential( #784\n",
    "            nn.Conv1d(in_channels=1,\n",
    "                  out_channels=num_hiddens // 2,\n",
    "                  kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                  out_channels=num_hiddens,\n",
    "                  kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv1d(in_channels=num_hiddens,\n",
    "                  out_channels=num_hiddens,\n",
    "                  kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "        )\n",
    "        self.pre_vq_conv = nn.Conv1d(in_channels=num_hiddens, \n",
    "                                  out_channels=latent_dim,\n",
    "                                  kernel_size=1, \n",
    "                                  stride=1)\n",
    "        \n",
    "        self.vq_vae = VectorQuantizer(num_embeddings, latent_dim,\n",
    "                                       commitment_cost)\n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(latent_dim * (data_len // (2 ** 3)), regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=latent_dim,\n",
    "                         out_channels=num_hiddens,\n",
    "                         kernel_size=3, \n",
    "                         stride=1, padding=1),\n",
    "            #torch.nn.Linear(num_hiddens, num_hiddens * (data_len // (2 ** 3))),\n",
    "            Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "            nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                  out_channels=num_hiddens,\n",
    "                  kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                  out_channels=num_hiddens // 2,\n",
    "                  kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                  out_channels=1,\n",
    "                  kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(dropout),\n",
    "            Trim(),  # 1x29x29 -> 1x28x28\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z = self.pre_vq_conv(x)\n",
    "        loss, encoded, perplexity, encoding = self.vq_vae(z)\n",
    "        #print(encoded.shape)\n",
    "        freq = self.regresion(encoded)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded,perplexity,loss,freq, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #784\n",
    "                nn.Conv1d(in_channels=1,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim),\n",
    "        )\n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Linear(latent_dim , regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(latent_dim, num_hiddens * (data_len // (2 ** 3))),\n",
    "                Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                Trim(),  # 1x29x29 -> 1x28x28\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        freq = self.regresion(encoder)\n",
    "        decoder = self.decoder(encoder)\n",
    "        return encoder,None, None, freq, decoder\n",
    "    \n",
    "    \n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "\n",
    "class Trim(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #784\n",
    "                nn.Conv1d(in_channels=1,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Flatten(),\n",
    "        )\n",
    "        self.z_mean = torch.nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim)\n",
    "        self.z_log_var = torch.nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim)\n",
    "        \n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Linear(latent_dim , regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(latent_dim, num_hiddens * (data_len // (2 ** 3))),\n",
    "                Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                Trim(),  # 1x29x29 -> 1x28x28\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "    def encoding_fn(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        return encoded\n",
    "    def reparameterize(self, z_mu, z_log_var):\n",
    "        eps = torch.randn(z_mu.size(0), z_mu.size(1), device=z_mu.device)\n",
    "        z = z_mu + eps * torch.exp(z_log_var/2.) \n",
    "        return z\n",
    "    def latent_sample(self, z_mu, z_log_var):\n",
    "        # the reparameterization trick\n",
    "        std = z_log_var.mul(0.5).exp_()\n",
    "        eps = torch.empty_like(std).normal_()\n",
    "        return eps.mul(std).add_(z_mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.latent_sample(z_mean, z_log_var)\n",
    "        freq = self.regresion(encoded)#torch.cat((z_mean, z_log_var), dim = 1))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded,z_mean,z_log_var,freq, decoded\n",
    "\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_hiddens, kernel_size, data_len, latent_dim, regression_hidden, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential( #784\n",
    "                nn.Conv1d(in_channels=1,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size, stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size  // 2 // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size  // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(num_hiddens * (data_len // (2 ** 3)), latent_dim),\n",
    "        )\n",
    "        self.regresion = nn.Sequential(\n",
    "                nn.Linear(latent_dim , regression_hidden),\n",
    "                nn.Linear(regression_hidden , 6),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(latent_dim, num_hiddens * (data_len // (2 ** 3))),\n",
    "                Reshape(-1, num_hiddens, (data_len // (2 ** 3))),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=kernel_size // 4, stride=2, padding = kernel_size // 4 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens,\n",
    "                      out_channels=num_hiddens // 2,\n",
    "                      kernel_size=kernel_size // 2, stride=2, padding = kernel_size // 2 // 2 - 1, bias=False),\n",
    "                nn.BatchNorm1d(num_hiddens // 2),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose1d(in_channels=num_hiddens // 2,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=kernel_size , stride=2, padding = kernel_size  // 2 - 1, bias=False),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Dropout(dropout),\n",
    "                Trim(),  # 1x29x29 -> 1x28x28\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        freq = self.regresion(encoder)\n",
    "        decoder = self.decoder(encoder)\n",
    "        return encoder,None, None, freq, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "#summary(model, (1,256), batch_size=-1, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = 256\n",
    "encoded_type = \"RAW\"\n",
    "model_type = \"VQVAE\"\n",
    "wandb.init(project=\"Six Cases\", notes=\"FinishingResults\",tags=[\"VQVAEAE\", \"paper5\"],config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6",
    "tags": []
   },
   "source": [
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SWEEP == 1:\n",
    "    sweep_config = {\n",
    "      \"name\" : \"regression_lantent\",\n",
    "      \"method\" : \"grid\",\n",
    "      \"parameters\" : {\n",
    "          \"num_embeddings\":{\n",
    "              \"values\" : [32]\n",
    "          },\n",
    "          \"commitment_cost\":{\n",
    "              \"values\" : [ 0.7]\n",
    "          },\n",
    "        \"encoded_type\" : {\n",
    "          \"values\" : ['RAW', 'LORENTZ']\n",
    "        },\n",
    "         \"model_type\" : {\n",
    "          \"values\" : [\"AE\",\"VAE\",\"VQVAE\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config)\n",
    "    def train():\n",
    "        config = {\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"epochs\": NUM_EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"kernel_size\": kernel_size,\n",
    "            \"num_hiddens\": num_hiddens,\n",
    "            \"lantent_dim\": latent_dim,\n",
    "            \"regression_hidden\":regression_hidden,\n",
    "            \"freq_mult\": freq_mult,\n",
    "             \"dropout\": dropout,\n",
    "            \"best_perc\": 20,\n",
    "        }\n",
    "        with wandb.init(project=\"Six Cases\", notes=\"FinishingResults\",tags=[\"VQVAEAE\", \"paper5\"],config=config) as run:\n",
    "            config = wandb.config\n",
    "            model_type =  config[\"model_type\"]\n",
    "            encoded_type = config[\"encoded_type\"]\n",
    "            if model_type == \"AE\":\n",
    "                model = AE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim, \n",
    "                                 regression_hidden = regression_hidden, dropout = dropout)\n",
    "            if model_type == \"VAE\":\n",
    "                model = VAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                            regression_hidden = regression_hidden, dropout = dropout)\n",
    "            if model_type == \"VQVAE\":\n",
    "                model = VQVAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                      regression_hidden = regression_hidden, num_embeddings = config[\"num_embeddings\"], dropout = 0, commitment_cost = config[\"commitment_cost\"])\n",
    "            model.to(DEVICE)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "            log_dict = train_v1(num_epochs=NUM_EPOCHS, model=model, \n",
    "                                    optimizer=optimizer, device=DEVICE, freq_mult = freq_mult,\n",
    "                                    train_loader=train_loader,\n",
    "                                    worst_case_loader = train_loader_worst,\n",
    "                                    skip_epoch_stats=True,\n",
    "                                    logging_interval=200, wandb = wandb, model_type = model_type, encoded_type = encoded_type)\n",
    "            if SAVE_DATA == 1:\n",
    "                data = get_data_complete(filepath, model, \"cpu\", )\n",
    "                torch.save(model, \"models/\"+ run.name + \".model\")\n",
    "                log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)\n",
    "\n",
    "    \n",
    "    wandb.agent(sweep_id, function=train)\n",
    "if SWEEP == 0:\n",
    "    from torchvision import models\n",
    "    from torchsummary import summary\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "    if model_type == \"AE\":\n",
    "        model = AE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim, \n",
    "                         regression_hidden = regression_hidden, dropout = dropout)\n",
    "    if model_type == \"VAE\":\n",
    "        model = VAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                    regression_hidden = regression_hidden, dropout = dropout)\n",
    "    if model_type == \"VQVAE\":\n",
    "        model = VQVAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "                      regression_hidden = regression_hidden, num_embeddings = 32, dropout = 0, commitment_cost = 0.25)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "    #summary(model, (1,256), batch_size=-1, device='cuda')\n",
    "\n",
    "\n",
    "    log_dict = train_v1(num_epochs=NUM_EPOCHS, model=model, \n",
    "                            optimizer=optimizer, device=DEVICE, freq_mult = freq_mult,\n",
    "                            train_loader=train_loader,\n",
    "                            worst_case_loader = train_loader_worst,\n",
    "                            skip_epoch_stats=True,\n",
    "                            logging_interval=200, wandb = wandb,model_type = model_type, encoded_type = encoded_type)\n",
    "    if SAVE_DATA == 1:\n",
    "        data = get_data_complete(filepath, model, \"cpu\")\n",
    "        torch.save(model, \"models/\"+ wandb.run.name + \".model\")\n",
    "        log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    " data = get_data_complete(filepath, all_loader,  model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQVAE(num_hiddens = num_hiddens, kernel_size = kernel_size, data_len = data_len, latent_dim = latent_dim,\n",
    "              regression_hidden = regression_hidden, embedding_dim = 64, num_embeddings = 32, dropout = 0)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "summary(model, (1,256), batch_size=-1, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = corr_noise(data)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"VAE\"\n",
    "encoded_type = \"RAW\"\n",
    "base_path = \"images/\" + model_type + \"_\" + encoded_type + \"_\";\n",
    "path_loss_batch = base_path + \"loss.png\"\n",
    "plot_loss(log_dict, NUM_EPOCHS, model_type).savefig(path_loss_batch)\n",
    "wandb.log({\"loss_batch\": wandb.Image(path_loss_batch)})\n",
    "\n",
    "path_worst_residual_freq_loss = base_path + \"worst_residual_freq_loss.png\"\n",
    "plot_residual_loss(test_loader_worst, model, DEVICE, model_type = model_type, show = False).savefig(path_worst_residual_freq_loss)\n",
    "wandb.log({\"worst_residual_freq_loss\": wandb.Image(path_worst_residual_freq_loss)})\n",
    "\n",
    "\n",
    "path_test_residual_freq_loss = base_path + \"test_residual_freq_loss.png\"\n",
    "plot_residual_loss(test_loader, model, DEVICE, model_type = model_type, show = False).savefig(path_test_residual_freq_loss)\n",
    "wandb.log({\"test_residual_freq_loss\": wandb.Image(path_test_residual_freq_loss)})\n",
    "\n",
    "path_train_freq_qqplot = base_path + \"train_freq_qqplot.png\"\n",
    "plot_freq_loss(train_loader, model, DEVICE, model_type = model_type, show = False).savefig(path_train_freq_qqplot)\n",
    "wandb.log({\"train_freq_qqplot\": wandb.Image(path_train_freq_qqplot)})\n",
    "\n",
    "path_worst_freq_qqplot = base_path + \"worst_freq_qqplot.png\"\n",
    "plot_freq_loss(train_loader_worst, model, DEVICE, model_type = model_type, show = False).savefig(path_worst_freq_qqplot)\n",
    "wandb.log({\"worst_freq_qqplot\": wandb.Image(path_worst_freq_qqplot)})\n",
    "\n",
    "path_worst_cases = base_path + \"worst_cases.png\"\n",
    "plot_cases(test_loader_worst, model, DEVICE, model_type = model_type).savefig(path_worst_cases)\n",
    "wandb.log({\"worst_cases\": wandb.Image(path_worst_cases)})\n",
    "\n",
    "path_test_cases = base_path + \"test_cases.png\"\n",
    "plot_cases(test_loader, model, DEVICE, model_type = model_type).savefig(path_test_cases)\n",
    "wandb.log({\"test_cases\": wandb.Image(path_test_cases)})\n",
    "\n",
    "dict_freq = selected_freq(data)\n",
    "\n",
    "path_hist_freq = base_path + \"hist_freq.png\"\n",
    "plot_hist_freq(data).savefig(path_hist_freq)\n",
    "wandb.log({\"hist_freq\": wandb.Image(path_hist_freq)})\n",
    "\n",
    "for index_sr_mode in range(1,7):\n",
    "    freq_qqplot = base_path + str(index_sr_mode) + \"_freq_qqplot.png\"\n",
    "    plot_season(data, sr_mode=index_sr_mode, show = False).savefig(freq_qqplot)\n",
    "    wandb.log({ str(index_sr_mode) + \"_freq_qqplot\": wandb.Image(freq_qqplot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_result(wandb,NUM_EPOCHS,  model, DEVICE,data, log_dict,train_loader, test_loader, train_loader_worst,  model_type, encoded_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_log_model import log_result\n",
    "from sklearn import preprocessing    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = read_sr_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79281, 512)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"models/AE_RAW.model\")\n",
    "data = get_data_complete(filepath, model, \"cpu\")\n",
    "List = [model, data];\n",
    "Dict = {\"AE_RAW\":List}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_models import VQVAE, VAE, AutoEncoder, Reshape, Trim, VectorQuantizer\n",
    "model = torch.load(\"models/VQVAE_RAW.model\")\n",
    "values =  get_est(all_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79281, 1, 256)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_models import VQVAE, VAE, AutoEncoder, Reshape, Trim, VectorQuantizer\n",
    "from helper_train import get_data_complete\n",
    "import torch\n",
    "# load pickle module\n",
    "import pickle\n",
    "\n",
    "root = \"\"\n",
    "data_path = 'data'\n",
    "fit_sr = '\\\\SR_table_DL.mat'\n",
    "datapath = filepath = root + data_path + fit_sr;\n",
    "start_model_path = \"models/\"\n",
    "end_model_path = \".model\"\n",
    "models = [\"AE_RAW\", \"VAE_RAW\", \"VQVAE_RAW\", \"AE_LORENTZ\", \"VAE_LORENTZ\", \"VQVAE_LORENTZ\"]\n",
    "models_dict = {}\n",
    "for index_model in range(6):\n",
    "    model_name = models[index_model] \n",
    "    model_path = start_model_path + model_name + end_model_path\n",
    "    print(model_path)\n",
    "    model = torch.load(model_path)\n",
    "    data = get_data_complete(filepath, model, \"cpu\")\n",
    "    current_dict = {\"model\": model, \"data\": data}\n",
    "    models_dict[model_name] = current_dict\n",
    "        \n",
    "# create a binary pickle file \n",
    "f = open(\"models.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(models_dict,f)\n",
    "\n",
    "# close file\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:branch-env]",
   "language": "python",
   "name": "conda-env-branch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
